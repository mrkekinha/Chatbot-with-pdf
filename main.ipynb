{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "967c8059",
   "metadata": {},
   "source": [
    "#### importando as bibliotecas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17be33c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c466a36",
   "metadata": {},
   "source": [
    "##### carregando as variáveis de ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef2714d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv())\n",
    "\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dacca4",
   "metadata": {},
   "source": [
    "#### carregando o arquivo em pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "300d68bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"C:\\\\Users\\\\Maria Raquel\\\\Chatbot-with-pdf\\\\data\\\\2210.03629v3.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec00179",
   "metadata": {},
   "source": [
    "#### fatiamento do conteudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef137b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(separator=\"\\n\")\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970f9818",
   "metadata": {},
   "source": [
    "#### Gerando Embeddings (cohere) e Criando o Vetor com pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f492318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = CohereEmbeddings(model=\"embed-english-v3.0\", cohere_api_key=COHERE_API_KEY)\n",
    "index_name = \"rag-demo\"\n",
    "\n",
    "vectorstore_from_docs = PineconeVectorStore.from_documents(\n",
    "    docs, index_name=index_name, embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7c34538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='14798b56-c6ff-43c7-945f-07ebf51b2593', metadata={'author': '', 'creationdate': '2023-03-13T00:09:11+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2023-03-13T00:09:11+00:00', 'page': 8.0, 'page_label': '9', 'producer': 'pdfTeX-1.40.21', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'source': 'C:\\\\Users\\\\Maria Raquel\\\\Chatbot-with-pdf\\\\data\\\\2210.03629v3.pdf', 'subject': '', 'title': '', 'total_pages': 33.0, 'trapped': '/False'}, page_content='Published as a conference paper at ICLR 2023\\n5 R ELATED WORK\\nLanguage model for reasoning Perhaps the most well-known work of using LLMs for reasoning\\nis Chain-of-Thought (CoT) (Wei et al., 2022), which reveals the ability of LLMs to formulate their\\nown “thinking procedure” for problem solving. Several follow-up works have since been performed,\\nincluding least-to-most prompting for solving complicated tasks (Zhou et al., 2022), zero-shot-\\nCoT (Kojima et al., 2022), and reasoning with self-consistency (Wang et al., 2022a). Recently,\\n(Madaan & Yazdanbakhsh, 2022) systematically studied the formulation and structure of CoT, and\\nobserved that the presence of symbols, patterns and texts is crucial to the effectiveness of CoT. Other\\nwork has also been extended to more sophisticated reasoning architecture beyond simple prompting.\\nFor example Selection-Inference (Creswell et al., 2022) divides the reasoning process into two steps\\nof “selection” and “inference”. STaR (Zelikman et al., 2022) bootstraps the reasoning process by\\nﬁnetuning the model on correct rationales generated by the model itself. Faithful reasoning (Creswell\\n& Shanahan, 2022) decomposes multi-step reasoning into three steps, each performed by a dedicated\\nLM respectively. Similar approaches like Scratchpad (Nye et al., 2021), which ﬁnetunes a LM on\\nintermediate computation steps, also demonstrate improvement on multi-step computation problems.\\nIn contrast to these methods, ReAct performs more than just isolated, ﬁxed reasoning, and integrates\\nmodel actions and their corresponding observations into a coherent stream of inputs for the model to\\nreason more accurately and tackle tasks beyond reasoning (e.g. interactive decision making).\\nLanguage model for decision making The strong capability of LLMs has enabled them to perform\\ntasks beyond language generation, and it is becoming more popular to take advantage of LLMs as a\\npolicy model for decision making, especially in interactive environments. WebGPT (Nakano et al.,\\n2021) uses an LM to interact with web browsers, navigate through web pages, and infer answers to\\ncomplicated questions from ELI5 (Fan et al., 2019). In comparison to ReAct, WebGPT does not\\nexplicitly model the thinking and reasoning procedure, instead rely on expensive human feedback for\\nreinforcement learning. In conversation modeling, chatbots like BlenderBot (Shuster et al., 2022b)\\nand Sparrow (Glaese et al., 2022) and task-oriented dialogue systems like SimpleTOD (Hosseini-Asl\\net al., 2020) also train LMs to make decision about API calls. Unlike ReAct, they do not explicitly\\nconsider the reasoning procedure either, and also relies on expensive datasets and human feedback\\ncollections for policy learning. In contrast, ReAct learns a policy in a much cheaper way, since the\\ndecision making process only requires language description of the reasoning procedure.6\\nLLMS have also been increasingly employed in interactive and embodied environments for planning\\nand decision making. Perhaps most relevant to ReAct in this respect are SayCan (Ahn et al., 2022)\\nand Inner Monologue (Huang et al., 2022b), which use LLMs for robotic action planning and decision\\nmaking. In SayCan, LLMs were prompted to directly predict possible actions a robot can take, which\\nis then reranked by an affordance model grounded on the visual environments for ﬁnal prediction.\\nInner Monologue made further improvements by adding the eponymous “inner monologue\", which is\\nimplemented as injected feedback from the environment. To our knowledge, Inner Monologue is the\\nﬁrst work that demonstrates such a closed-loop system, which ReAct builds on. However, we argue\\nthat Inner Monologue does not truly comprise of inner thoughts — this is elaborated in Section 4. We\\nalso note that leveraging language as semantically-rich inputs in the process of interactive decision\\nmaking has been shown to be successful under other settings (Abramson et al., 2020; Karamcheti'), Document(id='bc4fb56c-3933-489a-b210-fafd0caf0e13', metadata={'author': '', 'creationdate': '2023-03-13T00:09:11+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2023-03-13T00:09:11+00:00', 'page': 8.0, 'page_label': '9', 'producer': 'pdfTeX-1.40.21', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'source': 'C:\\\\Users\\\\Maria Raquel\\\\Chatbot-with-pdf\\\\data\\\\2210.03629v3.pdf', 'subject': '', 'title': '', 'total_pages': 33.0, 'trapped': '/False'}, page_content='Published as a conference paper at ICLR 2023\\n5 R ELATED WORK\\nLanguage model for reasoning Perhaps the most well-known work of using LLMs for reasoning\\nis Chain-of-Thought (CoT) (Wei et al., 2022), which reveals the ability of LLMs to formulate their\\nown “thinking procedure” for problem solving. Several follow-up works have since been performed,\\nincluding least-to-most prompting for solving complicated tasks (Zhou et al., 2022), zero-shot-\\nCoT (Kojima et al., 2022), and reasoning with self-consistency (Wang et al., 2022a). Recently,\\n(Madaan & Yazdanbakhsh, 2022) systematically studied the formulation and structure of CoT, and\\nobserved that the presence of symbols, patterns and texts is crucial to the effectiveness of CoT. Other\\nwork has also been extended to more sophisticated reasoning architecture beyond simple prompting.\\nFor example Selection-Inference (Creswell et al., 2022) divides the reasoning process into two steps\\nof “selection” and “inference”. STaR (Zelikman et al., 2022) bootstraps the reasoning process by\\nﬁnetuning the model on correct rationales generated by the model itself. Faithful reasoning (Creswell\\n& Shanahan, 2022) decomposes multi-step reasoning into three steps, each performed by a dedicated\\nLM respectively. Similar approaches like Scratchpad (Nye et al., 2021), which ﬁnetunes a LM on\\nintermediate computation steps, also demonstrate improvement on multi-step computation problems.\\nIn contrast to these methods, ReAct performs more than just isolated, ﬁxed reasoning, and integrates\\nmodel actions and their corresponding observations into a coherent stream of inputs for the model to\\nreason more accurately and tackle tasks beyond reasoning (e.g. interactive decision making).\\nLanguage model for decision making The strong capability of LLMs has enabled them to perform\\ntasks beyond language generation, and it is becoming more popular to take advantage of LLMs as a\\npolicy model for decision making, especially in interactive environments. WebGPT (Nakano et al.,\\n2021) uses an LM to interact with web browsers, navigate through web pages, and infer answers to\\ncomplicated questions from ELI5 (Fan et al., 2019). In comparison to ReAct, WebGPT does not\\nexplicitly model the thinking and reasoning procedure, instead rely on expensive human feedback for\\nreinforcement learning. In conversation modeling, chatbots like BlenderBot (Shuster et al., 2022b)\\nand Sparrow (Glaese et al., 2022) and task-oriented dialogue systems like SimpleTOD (Hosseini-Asl\\net al., 2020) also train LMs to make decision about API calls. Unlike ReAct, they do not explicitly\\nconsider the reasoning procedure either, and also relies on expensive datasets and human feedback\\ncollections for policy learning. In contrast, ReAct learns a policy in a much cheaper way, since the\\ndecision making process only requires language description of the reasoning procedure.6\\nLLMS have also been increasingly employed in interactive and embodied environments for planning\\nand decision making. Perhaps most relevant to ReAct in this respect are SayCan (Ahn et al., 2022)\\nand Inner Monologue (Huang et al., 2022b), which use LLMs for robotic action planning and decision\\nmaking. In SayCan, LLMs were prompted to directly predict possible actions a robot can take, which\\nis then reranked by an affordance model grounded on the visual environments for ﬁnal prediction.\\nInner Monologue made further improvements by adding the eponymous “inner monologue\", which is\\nimplemented as injected feedback from the environment. To our knowledge, Inner Monologue is the\\nﬁrst work that demonstrates such a closed-loop system, which ReAct builds on. However, we argue\\nthat Inner Monologue does not truly comprise of inner thoughts — this is elaborated in Section 4. We\\nalso note that leveraging language as semantically-rich inputs in the process of interactive decision\\nmaking has been shown to be successful under other settings (Abramson et al., 2020; Karamcheti'), Document(id='5394810a-51d3-4fab-bc61-17adcc94ec7c', metadata={'source': 'C:\\\\Users\\\\Maria Raquel\\\\RAG_LLM_INTRODUCTION\\\\data\\\\mediumblog1.txt'}, page_content='Conclusion\\nVector databases are essential for building LLM applications, offering efficient management of high-dimensional data. Let me know your thoughts on the vector databases mentioned here, and feel free to share your experiences with them.\\n\\nHappy Building!\\n\\n\\nEjiro Onose'), Document(id='878b85b8-142f-46e8-8e14-7a95b601b693', metadata={'source': 'C:\\\\Users\\\\Maria Raquel\\\\RAG_LLM_INTRODUCTION\\\\data\\\\mediumblog1.txt'}, page_content='Conclusion\\nVector databases are essential for building LLM applications, offering efficient management of high-dimensional data. Let me know your thoughts on the vector databases mentioned here, and feel free to share your experiences with them.\\n\\nHappy Building!\\n\\n\\nEjiro Onose')]\n"
     ]
    }
   ],
   "source": [
    "vectorstore = PineconeVectorStore(index_name=index_name, embedding=embeddings)\n",
    "print(vectorstore.similarity_search(\"What is a llm?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd4d729",
   "metadata": {},
   "source": [
    "#### criando a memoria pro chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5e0c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abdaa5b",
   "metadata": {},
   "source": [
    "#### configurando a llm com o groq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bf82842",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    model=\"Gemma2-9b-It\",\n",
    "    groq_api_key=GROQ_API_KEY,\n",
    "    temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07820757",
   "metadata": {},
   "source": [
    "#### cadeia de respostas e perguntas com RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f81390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maria Raquel\\Chatbot-with-pdf\\venv\\Lib\\site-packages\\langsmith\\client.py:278: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "retrieval_qa_chat_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "combine_docs_chain = create_stuff_documents_chain(\n",
    "    llm, \n",
    "    retrieval_qa_chat_prompt\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78a2ca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = create_retrieval_chain(\n",
    "    vectorstore.as_retriever(), \n",
    "    combine_docs_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0013ef51",
   "metadata": {},
   "source": [
    "#### perguntando ao modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "421b660d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReAct is a method for training language models to perform complex reasoning tasks by prompting them to generate a sequence of thoughts and actions. \n",
      "\n",
      "It leverages the flexibility of language models to reason and act in an interactive manner, allowing them to retrieve information from external sources like Wikipedia and combine it with their internal knowledge. \n",
      "\n",
      "This approach results in interpretable and controllable decision-making processes, making it easier to understand and debug the reasoning behind the model's actions. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"What is ReAct in 3 sentences?\"})\n",
    "print(response['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
